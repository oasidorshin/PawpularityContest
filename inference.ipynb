{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9ab04",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 9.805456,
     "end_time": "2022-01-12T08:28:55.863082",
     "exception": false,
     "start_time": "2022-01-12T08:28:46.057626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, timeit, math, copy, random\n",
    "sys.path.append(\"../input/d/abhishek/timmmaster\")\n",
    "sys.path.append(\"../input/ttach003/ttach-0.0.3/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch import nn, optim\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import optuna\n",
    "\n",
    "import transformers\n",
    "\n",
    "import ttach as tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888465d2",
   "metadata": {
    "papermill": {
     "duration": 0.018711,
     "end_time": "2022-01-12T08:28:55.889814",
     "exception": false,
     "start_time": "2022-01-12T08:28:55.871103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config and seed\n",
    "\n",
    "class Config:\n",
    "    img_size = 224\n",
    "    n_splits = 10\n",
    "    seed = 42\n",
    "    n_bins = 20 # for validation\n",
    "    \n",
    "    device = \"cuda\"\n",
    "    batch_size = 64\n",
    "    num_workers = 2\n",
    "    \n",
    "    inference_oof = False\n",
    "    inference_test = True\n",
    "    \n",
    "      \n",
    "cfg = Config\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791f4a1",
   "metadata": {
    "papermill": {
     "duration": 0.086136,
     "end_time": "2022-01-12T08:28:55.983778",
     "exception": false,
     "start_time": "2022-01-12T08:28:55.897642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, transform=None, folder = \"train\"):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load labels\n",
    "        self.df = pd.read_csv(f\"../input/petfinder-pawpularity-score/{folder}.csv\")\n",
    "        self.folder = folder\n",
    "                 \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_ = self.df.iloc[idx][\"Id\"]\n",
    "        image = cv2.imread(f\"../input/petfinder-pawpularity-score/{self.folder}/{id_}.jpg\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float64)\n",
    "        \n",
    "        if self.folder == \"train\":\n",
    "            label = self.df.iloc[idx]['Pawpularity']\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]\n",
    "        \n",
    "        return id_, image, torch.from_numpy(np.array(label)).float()\n",
    "\n",
    "test_transform224 = A.Compose([\n",
    "    A.SmallestMaxSize(224),\n",
    "    A.CenterCrop(224, 224),\n",
    "    A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform380 = A.Compose([\n",
    "    A.SmallestMaxSize(380),\n",
    "    A.CenterCrop(380, 380),\n",
    "    A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform384 = A.Compose([\n",
    "    A.SmallestMaxSize(384),\n",
    "    A.CenterCrop(384, 384),\n",
    "    A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_dataset224 = ImgDataset(transform = test_transform224, folder= \"train\")\n",
    "test_dataset224 = ImgDataset(transform = test_transform224, folder= \"test\")\n",
    "\n",
    "val_dataset380 = ImgDataset(transform = test_transform380, folder= \"train\")\n",
    "test_dataset380 = ImgDataset(transform = test_transform380, folder= \"test\")\n",
    "\n",
    "val_dataset384 = ImgDataset(transform = test_transform384, folder= \"train\")\n",
    "test_dataset384 = ImgDataset(transform = test_transform384, folder= \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbecfb",
   "metadata": {
    "papermill": {
     "duration": 0.014672,
     "end_time": "2022-01-12T08:28:56.006114",
     "exception": false,
     "start_time": "2022-01-12T08:28:55.991442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "def validation():\n",
    "    df = pd.read_csv(f\"../input/petfinder-pawpularity-score/train.csv\")\n",
    "    labels = pd.cut(np.array(df[\"Pawpularity\"]), bins=cfg.n_bins, labels=False)\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits = cfg.n_splits, shuffle = True, random_state = cfg.seed)\n",
    "    splits = splitter.split(labels, labels)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c9b53",
   "metadata": {
    "papermill": {
     "duration": 0.021857,
     "end_time": "2022-01-12T08:28:56.036045",
     "exception": false,
     "start_time": "2022-01-12T08:28:56.014188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "class BaseSwin(nn.Module):\n",
    "    def __init__(self, name=\"swin_large_patch4_window7_224\", pretrained=True, n_classes = 1):\n",
    "        super(BaseSwin, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=pretrained)\n",
    "        self.n_classes = n_classes\n",
    "        # self.model.head = nn.Sequential(nn.Dropout(p =  dropout), nn.Linear(self.model.head.in_features, 1))\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        if self.n_classes == 1:\n",
    "            return x.ravel()\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, name=\"ig_resnext101_32x8d\", pretrained=True, n_classes = 1):\n",
    "        super(BaseCNN, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=pretrained)\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = self.model.num_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(self.n_features, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x)\n",
    "        if self.n_classes == 1:\n",
    "            return x.ravel()\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "class BaseCNN_effnet(nn.Module):\n",
    "    def __init__(self, name=\"tf_efficientnet_b4_ns\", pretrained=True, n_classes = 1):\n",
    "        super(BaseCNN_effnet, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=pretrained)\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.fc = nn.Linear(self.n_features, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.fc(x)\n",
    "        if self.n_classes == 1:\n",
    "            return x.ravel()\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fb530",
   "metadata": {
    "papermill": {
     "duration": 4.625246,
     "end_time": "2022-01-12T08:29:00.668841",
     "exception": false,
     "start_time": "2022-01-12T08:28:56.043595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "CENTER_20 = torch.arange(100 / 20 / 2, 100, 100 / 20).cuda()\n",
    "AVERAGE_20 = torch.tensor([ 3.07883817,  8.20731707, 13.16618076, 18.31838565, 23.16625717,\n",
    "       28.00385109, 32.86976048, 37.88047809, 42.79871795, 47.91766724,\n",
    "       53.01474201, 58.00314465, 63.04562738, 67.82681564, 72.77844311,\n",
    "       77.80508475, 82.81818182, 87.72972973, 92.86363636, 99.70186335]).cuda()\n",
    "\n",
    "def inference_bce_scaled(preds):\n",
    "    # Inference function transforming model output to predictions\n",
    "    return sigmoid(preds) * 100\n",
    "\n",
    "def inference_ce(preds, mode, values):\n",
    "    \"\"\"\n",
    "    mode : \"argmax\", \"average\"\n",
    "    values : \"center\", \"average\"\n",
    "    \"\"\"\n",
    "    if mode == \"argmax\":\n",
    "        preds_modif = torch.zeros_like(preds)\n",
    "        preds_modif[torch.arange(preds.shape[0]), torch.argmax(preds, dim=1)] = 1\n",
    "    elif mode == \"average\":\n",
    "        preds_modif = F.softmax(preds, dim=1)\n",
    "\n",
    "    if values == \"center\":\n",
    "        vals = CENTER_20\n",
    "    elif values == \"average\":\n",
    "        vals = AVERAGE_20\n",
    "\n",
    "    return torch.sum(preds_modif * vals, dim=1)\n",
    "\n",
    "def inference_oof(model_class, model_params, weights_path, dataset, inference_function, train_df, columnname = \"model1\"):\n",
    "    splits = validation()\n",
    "    \n",
    "    device = cfg.device\n",
    "    \n",
    "    train_df[columnname] = -1\n",
    "    \n",
    "    for fold, (train_idx,val_idx) in enumerate(splits):\n",
    "        print(f\"Fold {fold + 1}\", \"\\n\")\n",
    "        \n",
    "        model = model_class(**model_params)\n",
    "        model.to(device)\n",
    "        \n",
    "        filename = f'{weights_path}/fold_{fold}.pth'\n",
    "        model.load_state_dict(torch.load(filename, map_location=\"cuda\"))\n",
    "        model.eval()\n",
    "        \n",
    "        model = tta.ClassificationTTAWrapper(model, tta.aliases.hflip_transform(), merge_mode='mean')\n",
    "        \n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        dataloader = DataLoader(dataset, batch_size=cfg.batch_size, sampler=val_sampler, num_workers = cfg.num_workers, pin_memory = True)\n",
    "        \n",
    "        for id_, X, target in tqdm(dataloader):\n",
    "            with torch.no_grad():\n",
    "                X, target = X.to(device), target.to(device)\n",
    "\n",
    "                output = model(X)\n",
    "                preds = inference_function(output)\n",
    "                \n",
    "                train_df.loc[id_, columnname] = preds.detach().cpu().numpy()\n",
    "                \n",
    "def inference_test(model_class, model_params, weights_path, dataset, inference_function, submission_df, columnname = \"model1\"):\n",
    "    dataloader = DataLoader(dataset, batch_size=8, num_workers = 2)\n",
    "    df = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n",
    "    df.set_index(\"Id\", inplace = True)\n",
    "    device = cfg.device\n",
    "    \n",
    "    for fold in range(cfg.n_splits):\n",
    "        df[fold] = -1\n",
    "        print(f\"Fold {fold + 1}\", \"\\n\")\n",
    "        \n",
    "        model = model_class(**model_params)\n",
    "        model.to(device)\n",
    "        \n",
    "        filename = f'{weights_path}/fold_{fold}.pth'\n",
    "        model.load_state_dict(torch.load(filename, map_location=\"cuda\"))\n",
    "        model.eval()\n",
    "        \n",
    "        model = tta.ClassificationTTAWrapper(model, tta.aliases.hflip_transform(), merge_mode='mean')\n",
    "        \n",
    "        for id_, X, target in tqdm(dataloader):\n",
    "            with torch.no_grad():\n",
    "                X, target = X.to(device), target.to(device)\n",
    "\n",
    "                output = model(X)\n",
    "                preds = inference_function(output)\n",
    "                \n",
    "                df.loc[id_, fold] = preds.detach().cpu().numpy()\n",
    "    \n",
    "    columnnames = [x for x in range(cfg.n_splits)]\n",
    "    submission_df[columnname] = df[columnnames].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21a44a",
   "metadata": {
    "papermill": {
     "duration": 0.018526,
     "end_time": "2022-01-12T08:29:00.695154",
     "exception": false,
     "start_time": "2022-01-12T08:29:00.676628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OOF preds + blend\n",
    "if cfg.inference_oof:\n",
    "    train_df = pd.read_csv(f\"../input/petfinder-pawpularity-score/train.csv\")\n",
    "    train_df.set_index(\"Id\", inplace = True)\n",
    "    \n",
    "    inference_ce_average_center = lambda preds: inference_ce(preds, \"average\", \"center\")\n",
    "    inference_ce_average_average = lambda preds: inference_ce(preds, \"average\", \"average\")\n",
    "    \n",
    "    \"\"\"\n",
    "    # 224 vit model\n",
    "    params_224 = {\"name\": \"vit_large_patch16_224\", \"pretrained\" : False}\n",
    "    inference_oof(BaseSwin, params_224, \"../input/vit224bce\", val_dataset224, inference_bce_scaled, train_df, \"224vit\")\n",
    "    \n",
    "    # 384 model\n",
    "    params_384 = {\"name\": \"swin_large_patch4_window12_384\", \"pretrained\" : False}\n",
    "    inference_oof(BaseSwin, params_384, \"../input/petfinder3842\", val_dataset384, inference_bce_scaled, train_df, \"384\")\n",
    "    \n",
    "\n",
    "    # 224 model\n",
    "    params_224 = {\"name\": \"swin_large_patch4_window7_224\", \"pretrained\" : False}\n",
    "    inference_oof(BaseSwin, params_224, \"../input/bce-large-1-epoch\", val_dataset224, inference_bce_scaled, train_df, \"224\")\n",
    "    \"\"\"\n",
    "    # 224 xcit model\n",
    "    params_224 = {\"name\": \"xcit_small_24_p8_224_dist\", \"pretrained\" : False}\n",
    "    inference_oof(BaseSwin, params_224, \"../input/xcit224\", val_dataset224, inference_bce_scaled, train_df, \"224xcit\")\n",
    "    \n",
    "    # 224 CE model\n",
    "    params_224ce = {\"name\": \"swin_large_patch4_window7_224\", \"pretrained\" : False, \"n_classes\": 20}\n",
    "    inference_oof(BaseSwin, params_224ce, \"../input/petfinder224ce\", val_dataset224, inference_ce_average_center, train_df, \"224CE_center\")\n",
    "    \n",
    "    # 384 CE model\n",
    "    params_384ce = {\"name\": \"swin_large_patch4_window12_384\", \"pretrained\" : False, \"n_classes\": 20}\n",
    "    inference_oof(BaseSwin, params_384ce, \"../input/384cee\", val_dataset384, inference_ce_average_center, train_df, \"384CE_center\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_df.to_csv(\"oof_preds.csv\")\n",
    "    \n",
    "    \"\"\"\n",
    "    # Ridge OOF blender\n",
    "    from sklearn.linear_model import Ridge\n",
    "    blender = Ridge(alpha = 0.1, fit_intercept = False)\n",
    "    blender.fit(train_df[[\"224\", \"384\", \"224CE\"]], train_df[\"Pawpularity\"])\n",
    "    coef = blender.coef_\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rmse_mean = mean_squared_error((train_df[\"224\"] + train_df[\"384\"]) / 2, train_df[\"Pawpularity\"], squared = False)\n",
    "    rmse_blend = mean_squared_error(coef[0]*train_df[\"224\"] + coef[1]*train_df[\"384\"], train_df[\"Pawpularity\"], squared = False)\n",
    "    \n",
    "    print(coef, rmse_mean, rmse_blend)\n",
    "    \n",
    "    print(train_df[[\"224\", \"384\", \"224CE\"]].corr())\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b4ce2",
   "metadata": {
    "papermill": {
     "duration": 0.012933,
     "end_time": "2022-01-12T08:29:00.715661",
     "exception": false,
     "start_time": "2022-01-12T08:29:00.702728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mean_squared_error(0.25543955 * train_df[\"224\"] + 0.43732183 * train_df[\"384\"] + 0.3215622 * train_df[\"224CE\"], train_df[\"Pawpularity\"], squared = False)\n",
    "#mean_squared_error(0.25735024 * train_df[\"224\"] + 0.43644603 * train_df[\"384\"] + 0.31605065 * train_df[\"224CE\"], train_df[\"Pawpularity\"], squared = False)\n",
    "#mean_squared_error(0.28045218 * train_df[\"224\"] + 0.41132276 * train_df[\"384\"] + 0.31828948 * train_df[\"224CE\"], train_df[\"Pawpularity\"], squared = False)\n",
    "#mean_squared_error(train_df[\"224CE\"], train_df[\"Pawpularity\"], squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6dce0",
   "metadata": {
    "papermill": {
     "duration": 723.849798,
     "end_time": "2022-01-12T08:41:04.573036",
     "exception": false,
     "start_time": "2022-01-12T08:29:00.723238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "if cfg.inference_test:\n",
    "    submission_df = pd.read_csv(f\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "    submission_df.set_index(\"Id\", inplace = True)\n",
    "    \n",
    "    \n",
    "    # 224 model\n",
    "    params_224 = {\"name\": \"swin_large_patch4_window7_224\", \"pretrained\" : False}\n",
    "    inference_test(BaseSwin, params_224, \"../input/bce-large-1-epoch\", test_dataset224, inference_bce_scaled, submission_df, \"224\")\n",
    "\n",
    "    # 384 model\n",
    "    params_384 = {\"name\": \"swin_large_patch4_window12_384\", \"pretrained\" : False}\n",
    "    inference_test(BaseSwin, params_384, \"../input/petfinder3842\", test_dataset384, inference_bce_scaled, submission_df, \"384\")\n",
    "    \n",
    "    inference_ce_average_center = lambda preds: inference_ce(preds, \"average\", \"center\")\n",
    "    inference_ce_average_average = lambda preds: inference_ce(preds, \"average\", \"average\")\n",
    "    \n",
    "    # 384 CE model\n",
    "    params_384ce = {\"name\": \"swin_large_patch4_window12_384\", \"pretrained\" : False, \"n_classes\": 20}\n",
    "    inference_test(BaseSwin, params_384ce, \"../input/384cee\", test_dataset384, inference_ce_average_average, submission_df, \"384CE\")\n",
    "    \n",
    "    # 224 vit model\n",
    "    params_224vit = {\"name\": \"vit_large_patch16_224\", \"pretrained\" : False}\n",
    "    inference_test(BaseSwin, params_224vit, \"../input/vit224bce\", test_dataset224, inference_bce_scaled, submission_df, \"224vit\")\n",
    "    \n",
    "    # 384 vit model\n",
    "    params_384vit = {\"name\": \"vit_base_patch16_384\", \"pretrained\" : False}\n",
    "    inference_test(BaseSwin, params_384vit, \"../input/vit384\", test_dataset384, inference_bce_scaled, submission_df, \"384vit\")\n",
    "    \n",
    "    # Resnext model\n",
    "    params_resnext = {\"name\": \"ig_resnext101_32x8d\", \"pretrained\" : False}\n",
    "    inference_test(BaseCNN, params_resnext, \"../input/resnext\", test_dataset224, inference_bce_scaled, submission_df, \"resnext\")\n",
    "    \n",
    "    # Effnet model\n",
    "    params_effnet = {\"name\": \"tf_efficientnet_b4_ns\", \"pretrained\" : False}\n",
    "    inference_test(BaseCNN_effnet, params_effnet, \"../input/effnet\", test_dataset380, inference_bce_scaled, submission_df, \"effnet\")\n",
    "    \n",
    "    submission_df[\"Pawpularity\"] = 0.13080735 * submission_df[\"224\"] + \\\n",
    "                                   0.14383828 * submission_df[\"384\"] + \\\n",
    "                                   0.16241641 * submission_df[\"384CE\"] + \\\n",
    "                                   0.15283374 * submission_df[\"224vit\"] + \\\n",
    "                                   0.11407149 * submission_df[\"384vit\"] +\\\n",
    "                                   0.15194291 * submission_df[\"resnext\"] +\\\n",
    "                                   0.13068022 * submission_df[\"effnet\"]\n",
    "    submission_df.drop(columns = [\"224\", \"384\", \"384CE\", \"224vit\", \"384vit\", \"resnext\", \"effnet\"], inplace = True)\n",
    "    submission_df.to_csv(f'submission.csv')\n",
    "    \n",
    "    print(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 749.582686,
   "end_time": "2022-01-12T08:41:08.190057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-12T08:28:38.607371",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
